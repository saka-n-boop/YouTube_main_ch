import json
import os
import re
import sys
from datetime import datetime, timedelta
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from dateutil import parser as date_parser

SCOPES = ['https://www.googleapis.com/auth/spreadsheets']

def get_env_vars():
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã€èªè¨¼æƒ…å ±ã€ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å–å¾—"""
    api_key = os.environ.get("YOUTUBE_API_KEY")
    spreadsheet_id = os.environ.get("SPREADSHEET_ID")
    service_account_key = os.environ.get("GCP_SERVICE_ACCOUNT_KEY")

    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'YOUTUBE_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    if not spreadsheet_id:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'SPREADSHEET_ID' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    if not service_account_key:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'GCP_SERVICE_ACCOUNT_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)

    return api_key, spreadsheet_id, service_account_key

def read_channel_ids(file_path):
    """channel_ID.txt ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆé‡è¤‡æ’é™¤ï¼‰"""
    if not os.path.exists(file_path):
        print(f"ã‚¨ãƒ©ãƒ¼: {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)
        
    with open(file_path, 'r', encoding='utf-8') as file:
        channel_ids = [line.strip() for line in file if line.strip()]
    
    # é‡è¤‡ã‚’é™¤å»ã—ã¦ãƒªã‚¹ãƒˆåŒ–
    unique_ids = list(set(channel_ids))
    
    if not unique_ids:
        print("ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ãƒãƒ«IDãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
        
    return unique_ids

def iso8601_to_duration(iso_duration):
    """PTè¡¨è¨˜ï¼ˆYouTube ISO8601ï¼‰ã‚’HH:MM:SSåŒ–"""
    pattern = re.compile(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?')
    match = pattern.match(iso_duration)
    if not match:
        return "00:00:00"
    hours = int(match.group(1)) if match.group(1) else 0
    minutes = int(match.group(2)) if match.group(2) else 0
    seconds = int(match.group(3)) if match.group(3) else 0
    return str(timedelta(hours=hours, minutes=minutes, seconds=seconds))

def convert_to_japan_time(utc_time_str):
    """UTCæ™‚åˆ»æ–‡å­—åˆ—ã‚’JSTå¤‰æ›ã—è¡¨ç¤ºç”¨ã«"""
    # dateutilã‚’ä½¿ç”¨ã—ã¦æŸ”è»Ÿã«ãƒ‘ãƒ¼ã‚¹ï¼ˆãƒŸãƒªç§’ã®æœ‰ç„¡ãªã©ã«å¯¾å¿œï¼‰
    utc_dt = date_parser.parse(utc_time_str)
    japan_dt = utc_dt.astimezone(timedelta(hours=9)) # UTCã‚ªãƒ•ã‚»ãƒƒãƒˆè€ƒæ…®ãªã—ã®å ´åˆã¯ + timedelta(hours=9)
    # å˜ç´”ãªåŠ ç®—ã«ã™ã‚‹ãŸã‚tzinfoã‚’æ¶ˆã—ã¦è¨ˆç®—ï¼ˆAPIè¿”å´å€¤ã¯åŸºæœ¬çš„ã«UTC+00:00ãŒã¤ã„ã¦ã„ã‚‹ï¼‰
    japan_dt = utc_dt.replace(tzinfo=None) + timedelta(hours=9)
    return japan_dt.strftime("%Y/%m/%d %H:%M:%S")

def get_current_japan_time():
    """ç¾åœ¨æ™‚åˆ» (JSTè¡¨ç¤º)"""
    now_utc = datetime.utcnow()
    now_jst = now_utc + timedelta(hours=9)
    return now_jst.strftime("%Y/%m/%d %H:%M:%S")

def get_current_japan_digit_date():
    """ä»Šæ—¥ã®æ—¥ä»˜ (JST, ã‚·ãƒ¼ãƒˆåç”¨ 'YYYYMMDD' ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ)"""
    now_utc = datetime.utcnow()
    now_jst = now_utc + timedelta(hours=9)
    return now_jst.strftime("%Y%m%d")

def calc_engagement_rate(like_count, comment_count, view_count):
    """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ (ï¼…)"""
    if view_count == 0:
        return 0.0
    return round((like_count + comment_count) / view_count * 100, 2)

def get_uploads_playlist_id(youtube, channel_id):
    """ãƒãƒ£ãƒ³ãƒãƒ«IDã‹ã‚‰ã€Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆIDã€ã‚’å–å¾—"""
    response = youtube.channels().list(
        id=channel_id,
        part='contentDetails'
    ).execute()
    
    if not response['items']:
        return None
    
    return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']

def get_all_videos_since_2020(api_key, channel_id):
    """
    æŒ‡å®šãƒãƒ£ãƒ³ãƒãƒ«ã®2020å¹´ä»¥é™ã®å…¨å‹•ç”»ã‚’å–å¾—ï¼ˆPlaylistItemsä½¿ç”¨ï¼‰
    ã‚³ã‚¹ãƒˆ: ä½ (1req = 1unit)
    """
    youtube = build('youtube', 'v3', developerKey=api_key)
    
    # 1. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆIDã‚’å–å¾—
    uploads_playlist_id = get_uploads_playlist_id(youtube, channel_id)
    if not uploads_playlist_id:
        print(f"   âš ï¸ ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {channel_id}")
        return []

    # 2020å¹´1æœˆ1æ—¥ (UTC) ã‚’å¢ƒç•Œç·šã¨ã™ã‚‹
    cutoff_date = datetime(2020, 1, 1, 0, 0, 0)

    video_ids = []
    next_page_token = None
    is_fetching = True

    # 2. ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‹ã‚‰å‹•ç”»IDãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆæ–°ã—ã„é †ã«å–å¾—ã•ã‚Œã‚‹ï¼‰
    while is_fetching:
        pl_request = youtube.playlistItems().list(
            playlistId=uploads_playlist_id,
            part='snippet', # snippetã«publishedAtãŒå«ã¾ã‚Œã‚‹
            maxResults=50,
            pageToken=next_page_token
        )
        pl_response = pl_request.execute()

        for item in pl_response['items']:
            published_at_str = item['snippet']['publishedAt']
            # æ–‡å­—åˆ—ã‚’datetimeã«å¤‰æ›
            dt = date_parser.parse(published_at_str).replace(tzinfo=None)

            if dt < cutoff_date:
                # 2020å¹´ã‚ˆã‚Šå¤ããªã£ãŸã‚‰ãƒ«ãƒ¼ãƒ—çµ‚äº†
                is_fetching = False
                break
            
            video_ids.append(item['snippet']['resourceId']['videoId'])

        next_page_token = pl_response.get('nextPageToken')
        if not next_page_token:
            break

    # 3. é›†ã‚ãŸå‹•ç”»IDã‚’ä½¿ã£ã¦çµ±è¨ˆæƒ…å ±ï¼ˆå†ç”Ÿæ•°ãªã©ï¼‰ã‚’å–å¾—
    #    videos().listã¯ã‚³ã‚¹ãƒˆ1req = 1unit (IDæŒ‡å®šã®å ´åˆ)
    final_video_data = []
    
    # 50ä»¶ãšã¤ãƒãƒƒãƒå‡¦ç†
    for i in range(0, len(video_ids), 50):
        batch_ids = video_ids[i:i+50]
        try:
            vid_response = youtube.videos().list(
                part='snippet,statistics,contentDetails',
                id=','.join(batch_ids)
            ).execute()

            for item in vid_response['items']:
                snippet = item['snippet']
                statistics = item.get('statistics', {})
                content_details = item['contentDetails']

                final_video_data.append({
                    'title': snippet['title'],
                    'channel': snippet['channelTitle'],
                    'published_at': snippet['publishedAt'],
                    'video_id': item['id'],
                    'view_count': int(statistics.get('viewCount', 0)),
                    'like_count': int(statistics.get('likeCount', 0)),
                    'comment_count': int(statistics.get('commentCount', 0)),
                    'duration': content_details.get('duration', "PT0S")
                })
        except Exception as e:
            print(f"   âš ï¸ è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    return final_video_data

def export_to_google_sheet(video_data, spreadsheet_id, service_account_key, exec_time_jst, sheet_name):
    """Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å‡ºåŠ›"""
    credentials_dict = json.loads(service_account_key)
    creds = Credentials.from_service_account_info(credentials_dict, scopes=SCOPES)
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(spreadsheet_id)

    # ã‚·ãƒ¼ãƒˆä½œæˆã¾ãŸã¯å–å¾—
    try:
        worksheet = sh.add_worksheet(title=sheet_name, rows=str(len(video_data)+50), cols="20")
    except gspread.exceptions.APIError:
        # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ãã®ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã—ã¦ã‚¯ãƒªã‚¢
        worksheet = sh.worksheet(sheet_name)
        worksheet.clear()

    headers = [
        "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«", "ãƒãƒ£ãƒ³ãƒãƒ«å", "æŠ•ç¨¿æ—¥æ™‚ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰", "å‹•ç”»ID",
        "å‹•ç”»URL", "å†ç”Ÿå›æ•°", "é«˜è©•ä¾¡æ•°", "è¦–è´è€…ã‚³ãƒ¡ãƒ³ãƒˆæ•°", "å‹•ç”»ã®é•·ã•",
        "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡(%)", "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚é–“ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰"
    ]
    rows = []
    for video in video_data:
        engagement_rate = calc_engagement_rate(video['like_count'], video['comment_count'], video['view_count'])
        video_url = f"https://www.youtube.com/watch?v={video['video_id']}"
        rows.append([
            video['title'],
            video['channel'],
            convert_to_japan_time(video['published_at']),
            video['video_id'],
            video_url,
            video['view_count'],
            video['like_count'],
            video['comment_count'],
            iso8601_to_duration(video['duration']),
            engagement_rate,
            exec_time_jst
        ])
    
    # ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
    worksheet.update('A1', [headers])
    if rows:
        worksheet.update('A2', rows, value_input_option='USER_ENTERED')

def main():
    channel_id_file = 'channel_ID.txt'
    api_key, spreadsheet_id, service_account_key = get_env_vars()
    
    # ãƒãƒ£ãƒ³ãƒãƒ«IDèª­ã¿è¾¼ã¿ï¼ˆé‡è¤‡æ’é™¤æ¸ˆã¿ï¼‰
    channel_ids = read_channel_ids(channel_id_file)

    sheet_name = get_current_japan_digit_date()
    exec_time_jst = get_current_japan_time()

    print(f"â¡ï¸ YouTubeãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ (å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«: {len(channel_ids)}ä»¶, 2020å¹´ä»¥é™)")

    all_video_data = []

    for idx, channel_id in enumerate(channel_ids, 1):
        print(f"   [{idx}/{len(channel_ids)}] Channel ID: {channel_id} å‡¦ç†ä¸­...")
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã®å‹•ç”»å–å¾—
        channel_videos = get_all_videos_since_2020(api_key, channel_id)
        
        print(f"     -> {len(channel_videos)}ä»¶ å–å¾—å®Œäº†")
        all_video_data.extend(channel_videos)

    if not all_video_data:
        print("âš ï¸ å‹•ç”»ãŒ1ä»¶ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # å…¨ä½“ã®é‡è¤‡æ’é™¤ï¼ˆå¿µã®ãŸã‚video_idã§ï¼‰
    unique_videos = {v['video_id']: v for v in all_video_data}.values()
    final_list = list(unique_videos)

    # å†ç”Ÿå›æ•°é †ã«ã‚½ãƒ¼ãƒˆ
    final_list.sort(key=lambda x: x['view_count'], reverse=True)

    print(f"â¡ï¸ åˆè¨ˆ {len(final_list)} ä»¶ã®å‹•ç”»ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å‡ºåŠ›ã—ã¾ã™...")
    export_to_google_sheet(final_list, spreadsheet_id, service_account_key, exec_time_jst, sheet_name)
    print(f"ğŸ‰ å‡¦ç†å®Œäº†ï¼ˆã‚·ãƒ¼ãƒˆå: {sheet_name}ï¼‰")

if __name__ == "__main__":
    main()
